{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# load CIFAR10 test set\n",
        "(_, _), (x_test, y_test) = cifar10.load_data()\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "y_test = y_test.flatten()\n",
        "num_samples = len(y_test)\n",
        "\n",
        "print(\"Test samples:\", num_samples)\n",
        "\n",
        "# load the 5 models (adam_lr001 versions)\n",
        "models = []\n",
        "for i in range(5):\n",
        "    name = f\"adam_lr001_model_{i}.h5\"\n",
        "    print(\"loading:\", name)\n",
        "    m = load_model(name)\n",
        "    models.append(m)\n",
        "\n",
        "print(\"Finished loading all 5 models.\")\n",
        "\n",
        "# run predictions for each model\n",
        "all_preds = []\n",
        "for i, m in enumerate(models):\n",
        "    print(\"predicting with model\", i)\n",
        "    preds = m.predict(x_test, verbose=0)   # (10000, 10)\n",
        "    all_preds.append(preds)\n",
        "\n",
        "all_preds = np.array(all_preds)   # (5, 10000, 10)\n",
        "\n",
        "# compute max confidence for each model on each image\n",
        "confs = np.max(all_preds, axis=2)    # (5, 10000)\n",
        "\n",
        "# naive MCE with tau = 0.95\n",
        "tau = 0.95\n",
        "excluded = (confs >= tau).astype(int)   # 1 = exclude, 0 = keep\n",
        "\n",
        "# ensemble before MCE\n",
        "ens_before = np.mean(all_preds, axis=0)\n",
        "pred_before = np.argmax(ens_before, axis=1)\n",
        "acc_before = np.mean(pred_before == y_test)\n",
        "\n",
        "# ensemble after MCE\n",
        "ens_after = []\n",
        "for i in range(num_samples):\n",
        "    keep = np.where(excluded[:, i] == 0)[0]\n",
        "\n",
        "    if len(keep) == 0:\n",
        "        # fallback if every model is excluded\n",
        "        avg = np.ones(10) / 10\n",
        "    else:\n",
        "        avg = np.mean(all_preds[keep, i, :], axis=0)\n",
        "\n",
        "    ens_after.append(avg)\n",
        "\n",
        "ens_after = np.array(ens_after)\n",
        "pred_after = np.argmax(ens_after, axis=1)\n",
        "acc_after = np.mean(pred_after == y_test)\n",
        "\n",
        "# exclusion stats\n",
        "num_excluded_per_sample = np.sum(excluded, axis=0)\n",
        "exclusion_rate = np.mean(num_excluded_per_sample > 0)\n",
        "avg_num_excluded = np.mean(num_excluded_per_sample)\n",
        "\n",
        "# RESULTS\n",
        "print(\"MCE ORACLE RESULTS (τ = 0.95)\")\n",
        "print(\"Accuracy before MCE:\", round(acc_before, 4))\n",
        "print(\"Accuracy after  MCE:\", round(acc_after, 4))\n",
        "print(\"Samples with exclusions:\", round(exclusion_rate * 100, 2), \"%\")\n",
        "print(\"Average # models excluded:\", round(avg_num_excluded, 3))\n",
        "\n",
        "# per model details\n",
        "print(\"PER-MODEL RESULTS\")\n",
        "for i in range(5):\n",
        "    preds_i = np.argmax(all_preds[i], axis=1)\n",
        "    acc_i = np.mean(preds_i == y_test)\n",
        "\n",
        "    excl_cnt = np.sum(excluded[i])\n",
        "    excl_rate = excl_cnt / num_samples\n",
        "\n",
        "    print(f\"\\nModel {i}:\")\n",
        "    print(\"  Accuracy:\", round(acc_i, 4))\n",
        "    print(f\"  Excluded: {excl_cnt}/{num_samples}\")\n",
        "    print(\"  Exclusion Rate:\", round(excl_rate * 100, 2), \"%\")\n",
        "\n",
        "# example output for image 0\n",
        "print(\"SAMPLE 0 DETAILS\")\n",
        "print(\"Confidences:\", confs[:, 0])\n",
        "print(\"Excluded   :\", excluded[:, 0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPJ7GFMcSlkJ",
        "outputId": "ec2b6d95-ef1c-415d-ed57-709656426a77"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test samples: 10000\n",
            "loading: adam_lr001_model_0.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading: adam_lr001_model_1.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading: adam_lr001_model_2.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading: adam_lr001_model_3.h5\n",
            "loading: adam_lr001_model_4.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished loading all 5 models.\n",
            "predicting with model 0\n",
            "predicting with model 1\n",
            "predicting with model 2\n",
            "predicting with model 3\n",
            "predicting with model 4\n",
            "MCE ORACLE RESULTS (τ = 0.95)\n",
            "Accuracy before MCE: 0.2283\n",
            "Accuracy after  MCE: 0.1253\n",
            "Samples with exclusions: 100.0 %\n",
            "Average # models excluded: 4.468\n",
            "PER-MODEL RESULTS\n",
            "\n",
            "Model 0:\n",
            "  Accuracy: 0.1571\n",
            "  Excluded: 9521/10000\n",
            "  Exclusion Rate: 95.21 %\n",
            "\n",
            "Model 1:\n",
            "  Accuracy: 0.174\n",
            "  Excluded: 9607/10000\n",
            "  Exclusion Rate: 96.07 %\n",
            "\n",
            "Model 2:\n",
            "  Accuracy: 0.1717\n",
            "  Excluded: 9787/10000\n",
            "  Exclusion Rate: 97.87 %\n",
            "\n",
            "Model 3:\n",
            "  Accuracy: 0.2735\n",
            "  Excluded: 8950/10000\n",
            "  Exclusion Rate: 89.5 %\n",
            "\n",
            "Model 4:\n",
            "  Accuracy: 0.1952\n",
            "  Excluded: 6819/10000\n",
            "  Exclusion Rate: 68.19 %\n",
            "SAMPLE 0 DETAILS\n",
            "Confidences: [0.99999994 0.99999994 0.9998045  0.99999994 0.95953536]\n",
            "Excluded   : [1 1 1 1 1]\n"
          ]
        }
      ]
    }
  ]
}