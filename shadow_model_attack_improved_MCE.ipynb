{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4119263c-1998-4b82-9fdd-e5ef37f6d9ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4119263c-1998-4b82-9fdd-e5ef37f6d9ba",
        "outputId": "e8438baa-c6ca-4e01-dfac-9fb7ddfdad0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "#imports and setup\n",
        "\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset\n",
        "\n",
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from scipy.stats import entropy\n",
        "\n",
        "# Set device\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e667cda7-aae0-4a08-9f13-215e6387c0ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e667cda7-aae0-4a08-9f13-215e6387c0ec",
        "outputId": "e1b101b5-2a29-4d58-d5b1-35fda0037382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "37b7aedc-78aa-4ce8-a71b-ac3933deadbd",
      "metadata": {
        "id": "37b7aedc-78aa-4ce8-a71b-ac3933deadbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "621ffa09-6356-4352-90f6-bdf7d75c0741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 12.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Define the transformations (normalization is key for training)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # Normalization parameters for CIFAR-10\n",
        "    # mean for CIFAR-10 = (0.4914, 0.4822, 0.4465)\n",
        "    #std for CIFAR-10  = (0.2023, 0.1994, 0.2010)\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "# Load original datasets\n",
        "original_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "original_testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "8d6a288c-89b0-418a-8566-bfd03fb138c3",
      "metadata": {
        "id": "8d6a288c-89b0-418a-8566-bfd03fb138c3"
      },
      "outputs": [],
      "source": [
        "# Reproducibility\n",
        "SEED = 32\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# ---- AlexNet variant for CIFAR-10 (32x32) ----\n",
        "class CIFARAlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # 32x32 -> 32x32\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            # 32x32 -> 16x16\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # 16x16 -> 16x16\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            # 16x16 -> 8x8\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # 8x8 -> 8x8\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # 8x8 -> 8x8\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # 8x8 -> 8x8\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # 8x8 -> 4x4\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        # 256 * 4 * 4 = 4096\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256*4*4, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)  # (N, 256*4*4)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Augmentation for training (paper §6.3): flip, ±10° rotation, ±10% translate, ~0.2% zoom\n",
        "train_transform_w_aug = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.10, 0.10), scale=(0.998, 1.002)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# No-aug (for eval and loaders that shouldn't augment)\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "5239dc07-279e-441f-954b-37f231177d00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5239dc07-279e-441f-954b-37f231177d00",
        "outputId": "3f17fd2e-6ead-4862-a84d-21b217f1325e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Dataset Partition Summary =====\n",
            "Total CIFAR-10 Train Samples: 50000\n",
            "Total CIFAR-10 Test Samples:  10000\n",
            "\n",
            "\n",
            "--- Attacker Train Set ---\n",
            "Members (from train):      20000\n",
            "Non-members:   10000\n"
          ]
        }
      ],
      "source": [
        "# Use the already-downloaded datasets but re-wrap them with the correct transforms when needed\n",
        "full_train_eval = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=eval_transform)\n",
        "full_test_eval  = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=eval_transform)\n",
        "\n",
        "NUM_TRAIN = len(full_train_eval)   # 50_000\n",
        "NUM_TEST  = len(full_test_eval)    # 10_000\n",
        "\n",
        "#Attacker Dataset - 20K members from CIFAR training, 10K nonmembers from CIFAR training\n",
        "attacker_idxs = np.random.permutation(np.arange(NUM_TRAIN))\n",
        "\n",
        "shadow_member_idx = attacker_idxs[:20000]\n",
        "shadow_nonmembers_idx = attacker_idxs[20000:30000]\n",
        "\n",
        "Dtrain_attack_members = Subset(full_train_eval, shadow_member_idx.tolist())\n",
        "Dtrain_attack_nonmembers  = Subset(full_train_eval, shadow_nonmembers_idx.tolist())\n",
        "\n",
        "# === Summary of Dataset Partitioning (CIFAR-10) ===\n",
        "print(\"===== Dataset Partition Summary =====\")\n",
        "print(f\"Total CIFAR-10 Train Samples: {len(full_train_eval)}\")\n",
        "print(f\"Total CIFAR-10 Test Samples:  {len(full_test_eval)}\\n\")\n",
        "\n",
        "print(\"\\n--- Attacker Train Set ---\")\n",
        "print(f\"Members (from train):      {len(Dtrain_attack_members)}\")\n",
        "print(f\"Non-members:   {len(Dtrain_attack_nonmembers)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9d48ea46-a040-47c1-9785-dca396cb04a0",
      "metadata": {
        "id": "9d48ea46-a040-47c1-9785-dca396cb04a0"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "def make_subset_dataset(indices, with_aug: bool):\n",
        "    base = torchvision.datasets.CIFAR10(root='./data', train=True, download=False,\n",
        "                                        transform=train_transform_w_aug if with_aug else eval_transform)\n",
        "    return Subset(base, indices.tolist())\n",
        "\n",
        "train_loader = []\n",
        "eval_loader  = []\n",
        "\n",
        "ds_train = make_subset_dataset(shadow_member_idx, with_aug=True)\n",
        "ds_eval  = make_subset_dataset(shadow_nonmembers_idx, with_aug=False)\n",
        "train_loader.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True))\n",
        "eval_loader.append( DataLoader(ds_eval,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True))\n",
        "\n",
        "# Full test loader for reporting model accuracies (like Table 2)\n",
        "full_test_loader = DataLoader(full_test_eval, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5311ec60-cffa-41bf-807d-b291419865be",
      "metadata": {
        "id": "5311ec60-cffa-41bf-807d-b291419865be"
      },
      "outputs": [],
      "source": [
        "# models = []\n",
        "# acc_table = []\n",
        "# for i, tr_loader in enumerate(train_loader, start=1):\n",
        "#     print(f\"\\nTraining shadow_model (with augmentation)...\")\n",
        "#     net = build_model()\n",
        "#     net = train_one_model(net, tr_loader, epochs=60)\n",
        "\n",
        "#     # Store in-memory\n",
        "#     models.append(net)\n",
        "\n",
        "#     # Evaluate accuracy\n",
        "#     acc = accuracy(net, full_test_loader)\n",
        "#     acc_table.append((f\"f{i}\", acc))\n",
        "#     print(f\"Shadow model accuracy on CIFAR-10 test (with aug): {acc:.2f}%\")\n",
        "\n",
        "#      # ---- SAVE TO DISK ----\n",
        "#     torch.save(net.state_dict(), f\"shadow_model.pth\")\n",
        "#     print(f\"Saved model as shadow_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ec7f7c32-80e9-4175-a544-5409b309f60e",
      "metadata": {
        "id": "ec7f7c32-80e9-4175-a544-5409b309f60e"
      },
      "outputs": [],
      "source": [
        "# ---- weight init helper (optional) ----\n",
        "def kaiming_init(m):\n",
        "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "def build_model():\n",
        "    net = CIFARAlexNet(num_classes=10)\n",
        "    net.apply(kaiming_init)\n",
        "    return net\n",
        "\n",
        "def train_one_model(model, train_loader, epochs=60, device=device):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 45, 55], gamma=0.1)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running += loss.item() * xb.size(0)\n",
        "        scheduler.step()\n",
        "        if (epoch+1) % 5 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs} - loss: {running/len(train_loader.dataset):.4f}\")\n",
        "    return model\n",
        "\n",
        "@torch.no_grad()\n",
        "def accuracy(model, data_loader, device=device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for xb, yb in data_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        pred = torch.argmax(logits, dim=1)\n",
        "        correct += (pred == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "    return 100.0 * correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "639e62df-6643-41b3-b18a-c904193cd9aa",
      "metadata": {
        "id": "639e62df-6643-41b3-b18a-c904193cd9aa"
      },
      "outputs": [],
      "source": [
        "def load_model(path):\n",
        "    device = torch.device(\"cpu\")\n",
        "    model = build_model().to(device)\n",
        "    state_dict = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "shadow_path = \"shadow_model.pth\"\n",
        "shadow_model = load_model(shadow_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "7694e38d-5f25-4812-be21-e4cb65f5e49e",
      "metadata": {
        "id": "7694e38d-5f25-4812-be21-e4cb65f5e49e"
      },
      "outputs": [],
      "source": [
        "shadow_eval_members = make_subset_dataset(shadow_member_idx, with_aug=False)\n",
        "shadow_eval_nonmembers = make_subset_dataset(shadow_nonmembers_idx, with_aug=False)\n",
        "\n",
        "shadow_eval_members_loader = DataLoader(shadow_eval_members, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "shadow_eval_nonmembers_loader = DataLoader(shadow_eval_nonmembers, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a305815d-cb48-4d79-a7b3-4e7f41969a16",
      "metadata": {
        "id": "a305815d-cb48-4d79-a7b3-4e7f41969a16"
      },
      "outputs": [],
      "source": [
        "#collect features for training shadow model classifier\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\n",
        "def collect_features(model, data_loader, member_label, device = device):\n",
        "    model.eval()\n",
        "    all_features = []\n",
        "    all_membership = []\n",
        "\n",
        "    for xb, yb in data_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        logits = model(xb)\n",
        "\n",
        "        pred = torch.argmax(logits, dim=1)\n",
        "        correct = (pred == yb).float()\n",
        "\n",
        "        probs = F.softmax(logits, dim = 1)\n",
        "\n",
        "        max_prob, _ = probs.max(dim = 1)\n",
        "\n",
        "        loss = criterion(logits, yb)\n",
        "\n",
        "        eps = 1e-12\n",
        "        entropy = -(probs * (probs + eps).log()).sum(dim = 1)\n",
        "\n",
        "        top_values, _ = probs.topk(2, dim=1)\n",
        "        margin = top_values[:, 0] - top_values[:, 1]\n",
        "\n",
        "        model_features = torch.stack([correct, max_prob, loss, entropy, margin], dim = 1)\n",
        "\n",
        "        all_features.append(model_features.cpu())\n",
        "        all_membership.append(torch.full((model_features.size(0),), member_label, dtype  = torch.long))\n",
        "\n",
        "    all_features = torch.cat(all_features, dim = 0).detach().cpu().numpy()\n",
        "    all_membership = torch.cat(all_membership, dim = 0).detach().cpu().numpy()\n",
        "\n",
        "    return all_features, all_membership"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cc19e64a-6f56-4bc5-ae94-e8c00b16cb16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc19e64a-6f56-4bc5-ae94-e8c00b16cb16",
        "outputId": "36e9a7af-aa9b-43b6-b11b-5c5c52dcfa69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shadow Member Feature Shape: (20000, 5)\n",
            "Shadow Member Labels Shape: (20000,)\n",
            "Shadow Nonmember Feature Shape: (10000, 5)\n",
            "Shadow Nonmember Labels Shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "#collect the shadow model features which will be used to train the attacker\n",
        "shadow_x_member, shadow_y_member = collect_features(shadow_model, shadow_eval_members_loader, member_label = 1)\n",
        "shadow_x_nonmember, shadow_y_nonmember = collect_features(shadow_model, shadow_eval_nonmembers_loader, member_label = 0)\n",
        "\n",
        "#sanity check to make sure there are 20k members with 5 features\n",
        "print(\"Shadow Member Feature Shape:\", shadow_x_member.shape)\n",
        "print(\"Shadow Member Labels Shape:\", shadow_y_member.shape)\n",
        "\n",
        "#sanity check to make sure there are 10k nonmembers with 5 features\n",
        "print(\"Shadow Nonmember Feature Shape:\", shadow_x_nonmember.shape)\n",
        "print(\"Shadow Nonmember Labels Shape:\", shadow_y_nonmember.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f9afc5c2-d19f-43e5-aea0-fcaf7374f35b",
      "metadata": {
        "id": "f9afc5c2-d19f-43e5-aea0-fcaf7374f35b"
      },
      "outputs": [],
      "source": [
        "shadow_attack_x = np.vstack([shadow_x_member, shadow_x_nonmember])\n",
        "shadow_attack_y = np.concatenate([shadow_y_member, shadow_y_nonmember])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ac0de362-ca1c-40a9-be2e-198b06f14215",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac0de362-ca1c-40a9-be2e-198b06f14215",
        "outputId": "277e5eaa-f379-4975-d57f-7db1f7c4fe50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shadow AUC: 1.0\n",
            "Shadow Attack Advantage: 1.0\n"
          ]
        }
      ],
      "source": [
        "shadow_attack_x = np.vstack([shadow_x_member, shadow_x_nonmember])\n",
        "shadow_attack_y = np.concatenate([shadow_y_member, shadow_y_nonmember])\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators = 200, max_depth = None, min_samples_split = 2, min_samples_leaf = 1, n_jobs = -1, class_weight = \"balanced\")\n",
        "clf.fit(shadow_attack_x, shadow_attack_y)\n",
        "\n",
        "shadow_attack_scores = clf.predict_proba(shadow_attack_x)[:, 1]\n",
        "\n",
        "shadow_auc = roc_auc_score(shadow_attack_y, shadow_attack_scores)\n",
        "print(\"Shadow AUC:\", shadow_auc)\n",
        "\n",
        "shadow_fpr, shadow_tpr, thresholds = roc_curve(shadow_attack_y, shadow_attack_scores)\n",
        "shadow_advantage = (shadow_tpr - shadow_fpr).max()\n",
        "\n",
        "print(\"Shadow Attack Advantage:\", shadow_advantage)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c681b89e-0870-4015-92f8-fd4244f87c3a",
      "metadata": {
        "id": "c681b89e-0870-4015-92f8-fd4244f87c3a"
      },
      "source": [
        "# MCE CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5190a1d3-c644-4664-a2ac-567acf7215b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5190a1d3-c644-4664-a2ac-567acf7215b2",
        "outputId": "5b8d46c4-8799-4a4c-b28c-bd0dc1342c3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 test accuracy: 73.59\n"
          ]
        }
      ],
      "source": [
        "# Load the five models\n",
        "f1 = load_model(\"f1.pth\")\n",
        "f2 = load_model(\"f2.pth\")\n",
        "f3 = load_model(\"f3.pth\")\n",
        "f4 = load_model(\"f4.pth\")\n",
        "f5 = load_model(\"f5.pth\")\n",
        "\n",
        "models = [f1, f2, f3, f4, f5]\n",
        "\n",
        "# (Optional) double-check f1 accuracy achieved in the setup\n",
        "print(\"f1 test accuracy:\", accuracy(f1, full_test_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ea019d55-14e3-410c-bff3-b4ea081c8ca6",
      "metadata": {
        "id": "ea019d55-14e3-410c-bff3-b4ea081c8ca6"
      },
      "outputs": [],
      "source": [
        "#collect features from any of the models to use for attack\n",
        "def collect_features(dataset, models, member_label, attack_type, ece_scores, device = device):\n",
        "    all_features = []\n",
        "    all_membership = []\n",
        "    eps = 1e-12\n",
        "\n",
        "    for i in range(len(dataset)):\n",
        "        if i  % 1000 == 0:\n",
        "            print(i)\n",
        "        xb, yb = dataset[i]\n",
        "        xb = xb.to(device)\n",
        "\n",
        "        if torch.is_tensor(yb):\n",
        "            yb = int(yb.item())\n",
        "\n",
        "        #call specific prediction function for each attack type\n",
        "        if attack_type == 'CDE':\n",
        "            probs, excluded_idx = confidence_deviation_predict(xb, models, device)\n",
        "        elif attack_type == 'HCE':\n",
        "            probs, excluded_idx = calibration_weighted_predict(xb, models, device, ece_scores)\n",
        "        elif attack_type == 'KLD':\n",
        "            probs, excluded_idx = hybrid_kl_predict(xb, models, device)\n",
        "        else:\n",
        "            print(\"Error, no such attack function.\")\n",
        "        max_prob = float(probs.max())\n",
        "\n",
        "        pred = int(np.argmax(probs))\n",
        "        correct = 1.0 if pred == yb else 0.0\n",
        "\n",
        "        true_class = float(probs[yb])\n",
        "        loss = -np.log(true_class + eps)\n",
        "\n",
        "        entropy = -float(np.sum(probs * np.log(probs + eps)))\n",
        "\n",
        "        sorted_probs = np.sort(probs)[::-1]\n",
        "        margin = float(sorted_probs[0] - sorted_probs[1])\n",
        "\n",
        "        all_features.append([correct, max_prob, loss, entropy, margin])\n",
        "        all_membership.append(member_label)\n",
        "\n",
        "    all_features = np.array(all_features, dtype=np.float32)\n",
        "    all_membership = np.array(all_membership, dtype=np.int64)\n",
        "\n",
        "    return all_features, all_membership"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f5ba6349-77c9-4a46-a640-311b444e089e",
      "metadata": {
        "id": "f5ba6349-77c9-4a46-a640-311b444e089e"
      },
      "outputs": [],
      "source": [
        "attack_aucs = []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcde9b15-ddc5-4499-b96b-3d185aee8e96",
      "metadata": {
        "id": "bcde9b15-ddc5-4499-b96b-3d185aee8e96"
      },
      "source": [
        "# IMPROVED MCE ATTACK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a4742348-8001-47dc-80cf-39b37a98aa8e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4742348-8001-47dc-80cf-39b37a98aa8e",
        "outputId": "f22b40e7-b9d5-4d24-acf4-01d2fd5ebb15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- MIAShield Test Set ---\n",
            "Members (from train):      5000\n",
            "Non-members (from test):   5000\n"
          ]
        }
      ],
      "source": [
        "# ---- Disjoint split of the training set into n equal parts ----\n",
        "n = 5\n",
        "\n",
        "all_train_idx = np.arange(NUM_TRAIN)\n",
        "np.random.shuffle(all_train_idx)\n",
        "splits = np.array_split(all_train_idx, n)  # list of 5 arrays (~10k each)\n",
        "\n",
        "# ---- EO train set: 2.5k x n members (from train) + 5k non-members (from test) ----\n",
        "EO_MEM_PER_SPLIT = 2500\n",
        "eo_mem_indices = []\n",
        "for s in splits:\n",
        "    eo_mem_indices.extend(np.random.choice(s, size=EO_MEM_PER_SPLIT, replace=False))\n",
        "eo_mem_indices = np.array(eo_mem_indices)  # length = 12_500\n",
        "\n",
        "eo_nonmem_indices = np.random.choice(np.arange(NUM_TEST), size=5000, replace=False)\n",
        "\n",
        "Dtrain_EO_members     = Subset(full_train_eval, eo_mem_indices.tolist())\n",
        "Dtrain_EO_nonmembers  = Subset(full_test_eval,  eo_nonmem_indices.tolist())\n",
        "\n",
        "# ---- MIAShield test set: 5k members (from train) + 5k non-members (from test)\n",
        "# ensure disjointness with Dtrain_EO to avoid bias/leakage\n",
        "remaining_train = np.setdiff1d(all_train_idx, eo_mem_indices, assume_unique=False)\n",
        "remaining_test  = np.setdiff1d(np.arange(NUM_TEST), eo_nonmem_indices, assume_unique=False)\n",
        "test_mem_indices    = np.random.choice(remaining_train, size=5000, replace=False)\n",
        "test_nonmem_indices = np.random.choice(remaining_test,  size=5000, replace=False)\n",
        "\n",
        "Dtest_MIASHIELD_members    = Subset(full_train_eval, test_mem_indices.tolist())\n",
        "Dtest_MIASHIELD_nonmembers = Subset(full_test_eval,  test_nonmem_indices.tolist())\n",
        "\n",
        "# === Summary of Dataset Partitioning (CIFAR-10) ===\n",
        "print(\"\\n--- MIAShield Test Set ---\")\n",
        "print(f\"Members (from train):      {len(Dtest_MIASHIELD_members)}\")\n",
        "print(f\"Non-members (from test):   {len(Dtest_MIASHIELD_nonmembers)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f5251bb0-4e4f-48b6-8721-b506dc458db0",
      "metadata": {
        "id": "f5251bb0-4e4f-48b6-8721-b506dc458db0"
      },
      "outputs": [],
      "source": [
        "# EO & MIAShield loaders (evaluation only — no aug)\n",
        "loader_train_EO_mem    = DataLoader(Dtrain_EO_members,    batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "loader_train_EO_nonmem = DataLoader(Dtrain_EO_nonmembers, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "loader_test_MIASHIELD_mem    = DataLoader(Dtest_MIASHIELD_members,    batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "loader_test_MIASHIELD_nonmem = DataLoader(Dtest_MIASHIELD_nonmembers, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "77a591ef-ee59-4a1b-8838-e950aec509d4",
      "metadata": {
        "id": "77a591ef-ee59-4a1b-8838-e950aec509d4"
      },
      "outputs": [],
      "source": [
        "# --- 1. Confidence Deviation Exclusion (CDE) ---\n",
        "def confidence_deviation_predict(x_tensor, ensemble_models, device, **kwargs):\n",
        "  \"\"\"\n",
        "  Excludes the model whose confidence on the majority label deviates most\n",
        "  (absolute difference) from the ensemble mean.\n",
        "  \"\"\"\n",
        "  all_probs = []\n",
        "  for model in ensemble_models:\n",
        "    model.eval() # Set model to evaluation mode\n",
        "    with torch.no_grad():\n",
        "      output = model(x_tensor.unsqueeze(0).to(device))\n",
        "      all_probs.append(torch.softmax(output, dim=1).cpu().numpy()[0])\n",
        "  predictions = np.array(all_probs) # Shape: (5, 10)\n",
        "\n",
        "  # Identify Majority Label\n",
        "  top_labels = [np.argmax(p) for p in predictions]\n",
        "  if not top_labels:\n",
        "    return np.zeros(predictions.shape[1]), 0\n",
        "  majority_label = Counter(top_labels).most_common(1)[0][0]\n",
        "\n",
        "  # Calculate Deviation\n",
        "  target_confidence = predictions[:, majority_label]\n",
        "  mean_confidence = np.mean(target_confidence)\n",
        "  deviation = np.abs(target_confidence - mean_confidence)\n",
        "\n",
        "  # Exclude the outlier\n",
        "  excluded_idx = np.argmax(deviation)\n",
        "\n",
        "  remaining_preds = np.delete(predictions, excluded_idx, axis=0)\n",
        "  final_pred = np.mean(remaining_preds, axis=0)\n",
        "\n",
        "  return final_pred, excluded_idx\n",
        "\n",
        "# --- 2. Historical Calibration Error (HCE) Helpers ---\n",
        "def compute_ece(model, loader, device, n_bin=10):\n",
        "  \"\"\"\n",
        "  Calculates expected calibration error (ECE) for a single model.\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  bin_boundaries = torch.linspace(0, 1, n_bin + 1)\n",
        "  confidence_list = []\n",
        "  predictions_list = []\n",
        "  labels_list = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for xb, yb in loader:\n",
        "      xb, yb = xb.to(device), yb.to(device)\n",
        "      logits = model(xb)\n",
        "      probs = torch.softmax(logits, dim=1)\n",
        "      conf, preds = torch.max(probs, 1)\n",
        "      confidence_list.append(conf)\n",
        "      predictions_list.append(preds)\n",
        "      labels_list.append(yb)\n",
        "\n",
        "  confidence = torch.cat(confidence_list)\n",
        "  predictions = torch.cat(predictions_list)\n",
        "  labels = torch.cat(labels_list)\n",
        "  accuracies = predictions.eq(labels)\n",
        "\n",
        "  ece = torch.zeros(1, device=device)\n",
        "  for bin_lower, bin_upper in zip(bin_boundaries[:-1], bin_boundaries[1:]):\n",
        "    in_bin = confidence.gt(bin_lower.item()) * confidence.le(bin_upper.item())\n",
        "    prop_in_bin = in_bin.float().mean()\n",
        "    if prop_in_bin.item() > 0:\n",
        "      accuracy_in_bin = accuracies[in_bin].float().mean()\n",
        "      avg_confidence_in_bin = confidence[in_bin].mean()\n",
        "      ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
        "  return ece.item()\n",
        "\n",
        "def calibration_weighted_predict(x_tensor, ensemble_models, device, ece_scores=None):\n",
        "  \"\"\"\n",
        "  Excludes model based on Confidence weighted by historical calibration error.\n",
        "  Score = Confidence * (1 + ECE). Higher score = higher likelihood of being\n",
        "  excluded.\n",
        "  \"\"\"\n",
        "  if ece_scores is None:\n",
        "    raise ValueError(\"ECE scores must be provided.\")\n",
        "\n",
        "  all_probs = []\n",
        "  for model in ensemble_models:\n",
        "    model.eval() # Set model to evaluation\n",
        "    with torch.no_grad():\n",
        "      output = model(x_tensor.unsqueeze(0).to(device))\n",
        "      all_probs.append(torch.softmax(output, dim=1).cpu().numpy()[0])\n",
        "\n",
        "  predictions = np.array(all_probs) # Shape\n",
        "  top_labels = [np.argmax(p) for p in predictions]\n",
        "  majority_label = Counter(top_labels).most_common(1)[0][0]\n",
        "\n",
        "  target_confidence = predictions[:, majority_label]\n",
        "\n",
        "  # Weight the confidence by model's general calibration error\n",
        "  exclusion_scores = []\n",
        "  for i, conf in enumerate(target_confidence):\n",
        "    score = conf * (1.0 + ece_scores[i])\n",
        "    exclusion_scores.append(score)\n",
        "\n",
        "  excluded_idx = np.argmax(exclusion_scores)\n",
        "  remaining_preds = np.delete(predictions, excluded_idx, axis=0)\n",
        "  final_pred = np.mean(remaining_preds, axis=0)\n",
        "  return final_pred, excluded_idx\n",
        "\n",
        "# --- 3. Hybrid Approach (KL Divergence) ---\n",
        "def hybrid_kl_predict(x_tensor, ensemble_models, device, **kwargs):\n",
        "  \"\"\"\n",
        "  Excludes the model whose output distribution diverges most (KL Divergence)\n",
        "  from the consensus distribution of the ensemble.\n",
        "  \"\"\"\n",
        "  all_prods = []\n",
        "  for model in ensemble_models:\n",
        "    model.eval() # Set model to evaluation\n",
        "    with torch.no_grad():\n",
        "      output = model(x_tensor.unsqueeze(0).to(device))\n",
        "      all_prods.append(torch.softmax(output, dim=1).cpu().numpy()[0])\n",
        "\n",
        "  predictions = np.array(all_prods) # Shape\n",
        "\n",
        "  # Calculate Consensus (Mean Distribution)\n",
        "  consensus = np.mean(predictions, axis=0)\n",
        "\n",
        "  # Calculate KL Divergence for each model vs Consensus\n",
        "  # entropy(pk, qk) calculates KL(pk || qk)\n",
        "  kl_divergences = [entropy(pred, consensus) for pred in predictions]\n",
        "\n",
        "  excluded_idx = np.argmax(kl_divergences)\n",
        "  remaining_preds = np.delete(predictions, excluded_idx, axis=0)\n",
        "  final_pred = np.mean(remaining_preds, axis=0)\n",
        "  return final_pred, excluded_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83d0ee0a-79fd-4908-8769-3ded5289057b",
      "metadata": {
        "id": "83d0ee0a-79fd-4908-8769-3ded5289057b"
      },
      "source": [
        "##CDE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "92810585-ec30-4d1c-9804-32047972b03a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92810585-ec30-4d1c-9804-32047972b03a",
        "outputId": "f8d9b054-632d-4b99-81a1-c39199f2feff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n",
            "48000\n",
            "49000\n",
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "CDE Features:\n",
            "Member Feature Shape: (50000, 5)\n",
            "Member Labels Shape: (50000,)\n",
            "Nonmember Feature Shape: (10000, 5)\n",
            "Nonmember Labels Shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "#collect CDE features which will be used with classifer\n",
        "cde_x_member, cde_y_member = collect_features(full_train_eval, models, member_label = 1, attack_type = 'CDE', ece_scores = None, device = device)\n",
        "cde_x_nonmember, cde_y_nonmember = collect_features(full_test_eval, models, member_label = 0, attack_type = 'CDE', ece_scores = None, device = device)\n",
        "\n",
        "print(\"CDE Features:\")\n",
        "print(\"Member Feature Shape:\", cde_x_member.shape)\n",
        "print(\"Member Labels Shape:\", cde_y_member.shape)\n",
        "print(\"Nonmember Feature Shape:\", cde_x_nonmember.shape)\n",
        "print(\"Nonmember Labels Shape:\", cde_y_nonmember.shape)\n",
        "\n",
        "cde_attack_x = np.vstack([cde_x_member, cde_x_nonmember])\n",
        "cde_attack_y = np.concatenate([cde_y_member, cde_y_nonmember])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "b120f709-a43b-4402-b321-b37df2303fd5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b120f709-a43b-4402-b321-b37df2303fd5",
        "outputId": "b08f2f88-9c9f-4787-befc-3904e853d80a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CDE AUC: 0.510212668\n",
            "CDE Attack Advantage: 0.017320000000000002\n"
          ]
        }
      ],
      "source": [
        "cde_attack_scores = clf.predict_proba(cde_attack_x)[:, 1]\n",
        "\n",
        "cde_auc = roc_auc_score(cde_attack_y, cde_attack_scores)\n",
        "\n",
        "print(\"CDE AUC:\", cde_auc)\n",
        "\n",
        "cde_fpr, cde_tpr, thresholds = roc_curve(cde_attack_y, cde_attack_scores)\n",
        "cde_advantage = (cde_tpr - cde_fpr).max()\n",
        "\n",
        "print(\"CDE Attack Advantage:\", cde_advantage)\n",
        "\n",
        "attack_aucs.append({'model': 'CDE', 'AUC': cde_auc, 'Advantage': cde_advantage})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8d92e2f-3ff3-4058-8969-14a1777ae275",
      "metadata": {
        "id": "d8d92e2f-3ff3-4058-8969-14a1777ae275"
      },
      "source": [
        "##HCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ed48ba39-3d4b-4197-bc59-68f3c6eac1ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed48ba39-3d4b-4197-bc59-68f3c6eac1ea",
        "outputId": "3b18634b-adc3-4492-e6cb-a4ab53cd1a9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing ECE scores...\n",
            "ECE Scores: [0.09007111191749573, 0.08758401870727539, 0.0854107141494751, 0.1029433012008667, 0.07500015944242477]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- Setup: Calculate ECE Scores (Required for Strategy 2) ---\n",
        "print(\"Computing ECE scores...\")\n",
        "\n",
        "ece_scores = [compute_ece(m, loader_test_MIASHIELD_nonmem, device) for m in models]\n",
        "print(f\"ECE Scores: {ece_scores}\\n\")\n",
        "\n",
        "# --- Generic Evaluation Runner ---\n",
        "def run_evaluation(strategy, predict_fn, dataset, models, device, **kwargs):\n",
        "  correct = 0\n",
        "  exclusion_counts = np.zeros(len(models), dtype=int)\n",
        "  total_samples = len(dataset)\n",
        "\n",
        "  print(f\"--- Evaluating {strategy} ---\")\n",
        "\n",
        "  for i in range(total_samples):\n",
        "    x_tensor, y_true = dataset[i]\n",
        "\n",
        "    # Execute the specific prediction strategy\n",
        "    pred_probs, excluded = predict_fn(x_tensor, models, device, **kwargs)\n",
        "\n",
        "    y_pred = np.argmax(pred_probs)\n",
        "    if y_pred == y_true:\n",
        "      correct += 1\n",
        "    exclusion_counts[excluded] += 1\n",
        "\n",
        "  accuracy = correct / total_samples\n",
        "  print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "  print(f\"Exclusion Counts: {exclusion_counts.tolist()}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "f2cb62a3-1ca1-4b19-972e-25ff88962349",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2cb62a3-1ca1-4b19-972e-25ff88962349",
        "outputId": "aa6e1986-8400-4ab1-b9fb-98a4da05badb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n",
            "48000\n",
            "49000\n",
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "HCE Features:\n",
            "Member Feature Shape: (50000, 5)\n",
            "Member Labels Shape: (50000,)\n",
            "Nonmember Feature Shape: (10000, 5)\n",
            "Nonmember Labels Shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "#collect HCE features which will be used with classifer\n",
        "hce_x_member, hce_y_member = collect_features(full_train_eval, models, member_label = 1, attack_type = 'HCE', ece_scores = ece_scores, device = device)\n",
        "hce_x_nonmember, hce_y_nonmember = collect_features(full_test_eval, models, member_label = 0, attack_type = 'HCE', ece_scores = ece_scores, device = device)\n",
        "\n",
        "print(\"HCE Features:\")\n",
        "print(\"Member Feature Shape:\", hce_x_member.shape)\n",
        "print(\"Member Labels Shape:\", hce_y_member.shape)\n",
        "print(\"Nonmember Feature Shape:\", hce_x_nonmember.shape)\n",
        "print(\"Nonmember Labels Shape:\", hce_y_nonmember.shape)\n",
        "\n",
        "hce_attack_x = np.vstack([hce_x_member, hce_x_nonmember])\n",
        "hce_attack_y = np.concatenate([hce_y_member, hce_y_nonmember])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "46e1f64c-b2da-4113-b3be-80cef977d91a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46e1f64c-b2da-4113-b3be-80cef977d91a",
        "outputId": "349a0940-5bb7-457b-c145-f021be4b7d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HCE AUC: 0.508926113\n",
            "HCE Attack Advantage: 0.014880000000000004\n"
          ]
        }
      ],
      "source": [
        "hce_attack_scores = clf.predict_proba(hce_attack_x)[:, 1]\n",
        "\n",
        "hce_auc = roc_auc_score(hce_attack_y, hce_attack_scores)\n",
        "print(\"HCE AUC:\", hce_auc)\n",
        "\n",
        "hce_fpr, hce_tpr, thresholds = roc_curve(hce_attack_y, hce_attack_scores)\n",
        "hce_advantage = (hce_tpr - hce_fpr).max()\n",
        "\n",
        "print(\"HCE Attack Advantage:\", hce_advantage)\n",
        "\n",
        "attack_aucs.append({'model': 'HCE', 'AUC': hce_auc, 'Advantage': hce_advantage})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f302af6-9e60-448f-b15f-cd4f63fb139a",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "2f302af6-9e60-448f-b15f-cd4f63fb139a"
      },
      "source": [
        "##KLD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b1249331-ec58-4bfb-9c9f-0a2601cb8a09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1249331-ec58-4bfb-9c9f-0a2601cb8a09",
        "outputId": "c2237fd9-e1a9-49cb-a666-979e05d6a6e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n",
            "48000\n",
            "49000\n",
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "KLD Features:\n",
            "Member Feature Shape: (50000, 5)\n",
            "Member Labels Shape: (50000,)\n",
            "Nonmember Feature Shape: (10000, 5)\n",
            "Nonmember Labels Shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "#collect MCE features which will be used with classifer\n",
        "kld_x_member, kld_y_member = collect_features(full_train_eval, models, member_label = 1, attack_type = 'KLD', ece_scores = None, device = device)\n",
        "kld_x_nonmember, kld_y_nonmember = collect_features(full_test_eval, models, member_label = 0,  attack_type = 'KLD', ece_scores = None, device = device)\n",
        "\n",
        "print(\"KLD Features:\")\n",
        "print(\"Member Feature Shape:\", kld_x_member.shape)\n",
        "print(\"Member Labels Shape:\", kld_y_member.shape)\n",
        "print(\"Nonmember Feature Shape:\", kld_x_nonmember.shape)\n",
        "print(\"Nonmember Labels Shape:\", kld_y_nonmember.shape)\n",
        "\n",
        "kld_attack_x = np.vstack([kld_x_member, kld_x_nonmember])\n",
        "kld_attack_y = np.concatenate([kld_y_member, kld_y_nonmember])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "b6255d79-dcdd-4dac-81a2-ffc749b9f762",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6255d79-dcdd-4dac-81a2-ffc749b9f762",
        "outputId": "237d37f7-36db-4c8a-8d41-38869e0a63ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KLD AUC: 0.510310242\n",
            "KLD Attack Advantage: 0.017939999999999956\n"
          ]
        }
      ],
      "source": [
        "kld_attack_scores = clf.predict_proba(kld_attack_x)[:, 1]\n",
        "\n",
        "kld_auc = roc_auc_score(kld_attack_y, kld_attack_scores)\n",
        "\n",
        "print(\"KLD AUC:\", kld_auc)\n",
        "\n",
        "kld_fpr, kld_tpr, thresholds = roc_curve(kld_attack_y, kld_attack_scores)\n",
        "kld_advantage = (kld_tpr - kld_fpr).max()\n",
        "\n",
        "print(\"KLD Attack Advantage:\", kld_advantage)\n",
        "\n",
        "attack_aucs.append({'model': 'KLD', 'AUC': kld_auc, 'Advantage': kld_advantage})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "fe2cb710-43b7-4b18-96b7-bd4fac726b9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe2cb710-43b7-4b18-96b7-bd4fac726b9d",
        "outputId": "75664320-67b5-4466-d61b-be9ff14d94a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model under attack: CDE\n",
            "Attack AUC: 0.510212668\n",
            "Attack advantage: 0.017320000000000002 \n",
            "\n",
            "Model under attack: HCE\n",
            "Attack AUC: 0.508926113\n",
            "Attack advantage: 0.014880000000000004 \n",
            "\n",
            "Model under attack: KLD\n",
            "Attack AUC: 0.510310242\n",
            "Attack advantage: 0.017939999999999956 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for attack in attack_aucs:\n",
        "    print(f\"Model under attack: {attack['model']}\")\n",
        "    print(f\"Attack AUC: {attack['AUC']}\")\n",
        "    print(f\"Attack advantage: {attack['Advantage']} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "af196b6c-6bf5-436b-9c15-c3f8178343a7",
      "metadata": {
        "id": "af196b6c-6bf5-436b-9c15-c3f8178343a7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}