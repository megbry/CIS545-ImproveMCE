{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4119263c-1998-4b82-9fdd-e5ef37f6d9ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4119263c-1998-4b82-9fdd-e5ef37f6d9ba",
        "outputId": "ebd4b1b9-fc61-4587-de1e-17b764ad2c94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "#imports and setup\n",
        "\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split, Subset\n",
        "\n",
        "import numpy as np\n",
        "from collections import defaultdict, Counter\n",
        "import random\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "from scipy.stats import entropy\n",
        "\n",
        "# Set device\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "e667cda7-aae0-4a08-9f13-215e6387c0ec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e667cda7-aae0-4a08-9f13-215e6387c0ec",
        "outputId": "da61692b-9593-4695-9057-9eada414b72d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "37b7aedc-78aa-4ce8-a71b-ac3933deadbd",
      "metadata": {
        "id": "37b7aedc-78aa-4ce8-a71b-ac3933deadbd"
      },
      "outputs": [],
      "source": [
        "# Define the transformations (normalization is key for training)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    # Normalization parameters for CIFAR-10\n",
        "    # mean for CIFAR-10 = (0.4914, 0.4822, 0.4465)\n",
        "    #std for CIFAR-10  = (0.2023, 0.1994, 0.2010)\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])\n",
        "\n",
        "# Load original datasets\n",
        "original_trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "original_testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "8d6a288c-89b0-418a-8566-bfd03fb138c3",
      "metadata": {
        "id": "8d6a288c-89b0-418a-8566-bfd03fb138c3"
      },
      "outputs": [],
      "source": [
        "# Reproducibility\n",
        "SEED = 32\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# ---- AlexNet variant for CIFAR-10 (32x32) ----\n",
        "class CIFARAlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # 32x32 -> 32x32\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            # 32x32 -> 16x16\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # 16x16 -> 16x16\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            # 16x16 -> 8x8\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            # 8x8 -> 8x8\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # 8x8 -> 8x8\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # 8x8 -> 8x8\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # 8x8 -> 4x4\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        # 256 * 4 * 4 = 4096\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256*4*4, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)  # (N, 256*4*4)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Augmentation for training (paper §6.3): flip, ±10° rotation, ±10% translate, ~0.2% zoom\n",
        "train_transform_w_aug = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomAffine(degrees=10, translate=(0.10, 0.10), scale=(0.998, 1.002)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# No-aug (for eval and loaders that shouldn't augment)\n",
        "eval_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "5239dc07-279e-441f-954b-37f231177d00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5239dc07-279e-441f-954b-37f231177d00",
        "outputId": "e2f44714-c732-4236-d3af-50fd9697a0e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===== Dataset Partition Summary =====\n",
            "Total CIFAR-10 Train Samples: 50000\n",
            "Total CIFAR-10 Test Samples:  10000\n",
            "\n",
            "\n",
            "--- Attacker Train Set ---\n",
            "Members (from train):      20000\n",
            "Non-members:   10000\n"
          ]
        }
      ],
      "source": [
        "# Use the already-downloaded datasets but re-wrap them with the correct transforms when needed\n",
        "full_train_eval = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=eval_transform)\n",
        "full_test_eval  = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=eval_transform)\n",
        "\n",
        "NUM_TRAIN = len(full_train_eval)   # 50_000\n",
        "NUM_TEST  = len(full_test_eval)    # 10_000\n",
        "\n",
        "#Attacker Dataset - 20K members from CIFAR training, 10K nonmembers from CIFAR training\n",
        "attacker_idxs = np.random.permutation(np.arange(NUM_TRAIN))\n",
        "\n",
        "shadow_member_idx = attacker_idxs[:20000]\n",
        "shadow_nonmembers_idx = attacker_idxs[20000:30000]\n",
        "\n",
        "Dtrain_attack_members = Subset(full_train_eval, shadow_member_idx.tolist())\n",
        "Dtrain_attack_nonmembers  = Subset(full_train_eval, shadow_nonmembers_idx.tolist())\n",
        "\n",
        "# === Summary of Dataset Partitioning (CIFAR-10) ===\n",
        "print(\"===== Dataset Partition Summary =====\")\n",
        "print(f\"Total CIFAR-10 Train Samples: {len(full_train_eval)}\")\n",
        "print(f\"Total CIFAR-10 Test Samples:  {len(full_test_eval)}\\n\")\n",
        "\n",
        "print(\"\\n--- Attacker Train Set ---\")\n",
        "print(f\"Members (from train):      {len(Dtrain_attack_members)}\")\n",
        "print(f\"Non-members:   {len(Dtrain_attack_nonmembers)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "9d48ea46-a040-47c1-9785-dca396cb04a0",
      "metadata": {
        "id": "9d48ea46-a040-47c1-9785-dca396cb04a0"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "def make_subset_dataset(indices, with_aug: bool):\n",
        "    base = torchvision.datasets.CIFAR10(root='./data', train=True, download=False,\n",
        "                                        transform=train_transform_w_aug if with_aug else eval_transform)\n",
        "    return Subset(base, indices.tolist())\n",
        "\n",
        "train_loader = []\n",
        "eval_loader  = []\n",
        "\n",
        "ds_train = make_subset_dataset(shadow_member_idx, with_aug=True)\n",
        "ds_eval  = make_subset_dataset(shadow_nonmembers_idx, with_aug=False)\n",
        "train_loader.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True))\n",
        "eval_loader.append( DataLoader(ds_eval,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True))\n",
        "\n",
        "# Full test loader for reporting model accuracies (like Table 2)\n",
        "full_test_loader = DataLoader(full_test_eval, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "5311ec60-cffa-41bf-807d-b291419865be",
      "metadata": {
        "id": "5311ec60-cffa-41bf-807d-b291419865be"
      },
      "outputs": [],
      "source": [
        "# models = []\n",
        "# acc_table = []\n",
        "# for i, tr_loader in enumerate(train_loader, start=1):\n",
        "#     print(f\"\\nTraining shadow_model (with augmentation)...\")\n",
        "#     net = build_model()\n",
        "#     net = train_one_model(net, tr_loader, epochs=60)\n",
        "\n",
        "#     # Store in-memory\n",
        "#     models.append(net)\n",
        "\n",
        "#     # Evaluate accuracy\n",
        "#     acc = accuracy(net, full_test_loader)\n",
        "#     acc_table.append((f\"f{i}\", acc))\n",
        "#     print(f\"Shadow model accuracy on CIFAR-10 test (with aug): {acc:.2f}%\")\n",
        "\n",
        "#      # ---- SAVE TO DISK ----\n",
        "#     torch.save(net.state_dict(), f\"shadow_model.pth\")\n",
        "#     print(f\"Saved model as shadow_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "ec7f7c32-80e9-4175-a544-5409b309f60e",
      "metadata": {
        "id": "ec7f7c32-80e9-4175-a544-5409b309f60e"
      },
      "outputs": [],
      "source": [
        "# ---- weight init helper (optional) ----\n",
        "def kaiming_init(m):\n",
        "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "        if m.bias is not None:\n",
        "            nn.init.constant_(m.bias, 0.0)\n",
        "\n",
        "def build_model():\n",
        "    net = CIFARAlexNet(num_classes=10)\n",
        "    net.apply(kaiming_init)\n",
        "    return net\n",
        "\n",
        "def train_one_model(model, train_loader, epochs=60, device=device):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30, 45, 55], gamma=0.1)\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running = 0.0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            out = model(xb)\n",
        "            loss = criterion(out, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running += loss.item() * xb.size(0)\n",
        "        scheduler.step()\n",
        "        if (epoch+1) % 5 == 0:\n",
        "            print(f\"Epoch {epoch+1}/{epochs} - loss: {running/len(train_loader.dataset):.4f}\")\n",
        "    return model\n",
        "\n",
        "@torch.no_grad()\n",
        "def accuracy(model, data_loader, device=device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for xb, yb in data_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        logits = model(xb)\n",
        "        pred = torch.argmax(logits, dim=1)\n",
        "        correct += (pred == yb).sum().item()\n",
        "        total += yb.size(0)\n",
        "    return 100.0 * correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "639e62df-6643-41b3-b18a-c904193cd9aa",
      "metadata": {
        "id": "639e62df-6643-41b3-b18a-c904193cd9aa"
      },
      "outputs": [],
      "source": [
        "def load_model(path):\n",
        "    device = torch.device(\"cpu\")\n",
        "    model = build_model().to(device)\n",
        "    state_dict = torch.load(path, map_location=device)\n",
        "    model.load_state_dict(state_dict)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "shadow_path = \"shadow_model.pth\"\n",
        "shadow_model = load_model(shadow_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "7694e38d-5f25-4812-be21-e4cb65f5e49e",
      "metadata": {
        "id": "7694e38d-5f25-4812-be21-e4cb65f5e49e"
      },
      "outputs": [],
      "source": [
        "shadow_eval_members = make_subset_dataset(shadow_member_idx, with_aug=False)\n",
        "shadow_eval_nonmembers = make_subset_dataset(shadow_nonmembers_idx, with_aug=False)\n",
        "\n",
        "shadow_eval_members_loader = DataLoader(shadow_eval_members, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "shadow_eval_nonmembers_loader = DataLoader(shadow_eval_nonmembers, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "a305815d-cb48-4d79-a7b3-4e7f41969a16",
      "metadata": {
        "id": "a305815d-cb48-4d79-a7b3-4e7f41969a16"
      },
      "outputs": [],
      "source": [
        "#collect features for training shadow model classifier\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "\n",
        "def collect_features(model, data_loader, member_label, device = device):\n",
        "    model.eval()\n",
        "    all_features = []\n",
        "    all_membership = []\n",
        "\n",
        "    for xb, yb in data_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "\n",
        "        logits = model(xb)\n",
        "\n",
        "        pred = torch.argmax(logits, dim=1)\n",
        "        correct = (pred == yb).float()\n",
        "\n",
        "        probs = F.softmax(logits, dim = 1)\n",
        "\n",
        "        max_prob, _ = probs.max(dim = 1)\n",
        "\n",
        "        loss = criterion(logits, yb)\n",
        "\n",
        "        eps = 1e-12\n",
        "        entropy = -(probs * (probs + eps).log()).sum(dim = 1)\n",
        "\n",
        "        top_values, _ = probs.topk(2, dim=1)\n",
        "        margin = top_values[:, 0] - top_values[:, 1]\n",
        "\n",
        "        model_features = torch.stack([correct, max_prob, loss, entropy, margin], dim = 1)\n",
        "\n",
        "        all_features.append(model_features.cpu())\n",
        "        all_membership.append(torch.full((model_features.size(0),), member_label, dtype  = torch.long))\n",
        "\n",
        "    all_features = torch.cat(all_features, dim = 0).detach().cpu().numpy()\n",
        "    all_membership = torch.cat(all_membership, dim = 0).detach().cpu().numpy()\n",
        "\n",
        "    return all_features, all_membership"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "cc19e64a-6f56-4bc5-ae94-e8c00b16cb16",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc19e64a-6f56-4bc5-ae94-e8c00b16cb16",
        "outputId": "28accbce-1d93-4b14-ae04-2e922fb85f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shadow Member Feature Shape: (20000, 5)\n",
            "Shadow Member Labels Shape: (20000,)\n",
            "Shadow Nonmember Feature Shape: (10000, 5)\n",
            "Shadow Nonmember Labels Shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "#collect the shadow model features which will be used to train the attacker\n",
        "shadow_x_member, shadow_y_member = collect_features(shadow_model, shadow_eval_members_loader, member_label = 1)\n",
        "shadow_x_nonmember, shadow_y_nonmember = collect_features(shadow_model, shadow_eval_nonmembers_loader, member_label = 0)\n",
        "\n",
        "#sanity check to make sure there are 20k members with 5 features\n",
        "print(\"Shadow Member Feature Shape:\", shadow_x_member.shape)\n",
        "print(\"Shadow Member Labels Shape:\", shadow_y_member.shape)\n",
        "\n",
        "#sanity check to make sure there are 10k nonmembers with 5 features\n",
        "print(\"Shadow Nonmember Feature Shape:\", shadow_x_nonmember.shape)\n",
        "print(\"Shadow Nonmember Labels Shape:\", shadow_y_nonmember.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "f9afc5c2-d19f-43e5-aea0-fcaf7374f35b",
      "metadata": {
        "id": "f9afc5c2-d19f-43e5-aea0-fcaf7374f35b"
      },
      "outputs": [],
      "source": [
        "shadow_attack_x = np.vstack([shadow_x_member, shadow_x_nonmember])\n",
        "shadow_attack_y = np.concatenate([shadow_y_member, shadow_y_nonmember])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "ac0de362-ca1c-40a9-be2e-198b06f14215",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac0de362-ca1c-40a9-be2e-198b06f14215",
        "outputId": "82128fec-b5f5-47bb-b542-076813279de7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shadow AUC: 1.0\n",
            "Shadow Attack Advantage: 1.0\n"
          ]
        }
      ],
      "source": [
        "shadow_attack_x = np.vstack([shadow_x_member, shadow_x_nonmember])\n",
        "shadow_attack_y = np.concatenate([shadow_y_member, shadow_y_nonmember])\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators = 200, max_depth = None, min_samples_split = 2, min_samples_leaf = 1, n_jobs = -1, class_weight = \"balanced\")\n",
        "clf.fit(shadow_attack_x, shadow_attack_y)\n",
        "\n",
        "shadow_attack_scores = clf.predict_proba(shadow_attack_x)[:, 1]\n",
        "\n",
        "shadow_auc = roc_auc_score(shadow_attack_y, shadow_attack_scores)\n",
        "print(\"Shadow AUC:\", shadow_auc)\n",
        "\n",
        "shadow_fpr, shadow_tpr, thresholds = roc_curve(shadow_attack_y, shadow_attack_scores)\n",
        "shadow_advantage = (shadow_tpr - shadow_fpr).max()\n",
        "\n",
        "print(\"Shadow Attack Advantage:\", shadow_advantage)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c681b89e-0870-4015-92f8-fd4244f87c3a",
      "metadata": {
        "id": "c681b89e-0870-4015-92f8-fd4244f87c3a"
      },
      "source": [
        "# MCE CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "5190a1d3-c644-4664-a2ac-567acf7215b2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5190a1d3-c644-4664-a2ac-567acf7215b2",
        "outputId": "5a7a998c-d90b-4299-fd95-84100ad8bef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 test accuracy: 73.59\n"
          ]
        }
      ],
      "source": [
        "# Load the five models\n",
        "f1 = load_model(\"f1.pth\")\n",
        "f2 = load_model(\"f2.pth\")\n",
        "f3 = load_model(\"f3.pth\")\n",
        "f4 = load_model(\"f4.pth\")\n",
        "f5 = load_model(\"f5.pth\")\n",
        "\n",
        "models = [f1, f2, f3, f4, f5]\n",
        "\n",
        "# (Optional) double-check f1 accuracy achieved in the setup\n",
        "print(\"f1 test accuracy:\", accuracy(f1, full_test_loader))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ea019d55-14e3-410c-bff3-b4ea081c8ca6",
      "metadata": {
        "id": "ea019d55-14e3-410c-bff3-b4ea081c8ca6"
      },
      "outputs": [],
      "source": [
        "#collect features from any of the models to use for attack\n",
        "def collect_features(dataset, models, member_label, attack_type, ece_scores, device = device):\n",
        "    all_features = []\n",
        "    all_membership = []\n",
        "    eps = 1e-12\n",
        "\n",
        "    for i in range(len(dataset)):\n",
        "        if i  % 1000 == 0:\n",
        "            print(i)\n",
        "        xb, yb = dataset[i]\n",
        "        xb = xb.to(device)\n",
        "\n",
        "        if torch.is_tensor(yb):\n",
        "            yb = int(yb.item())\n",
        "\n",
        "        #call specific prediction function for each attack type\n",
        "        if attack_type == 'CDE':\n",
        "            probs, excluded_idx = confidence_deviation_predict(xb, models, device)\n",
        "        elif attack_type == 'HCE':\n",
        "            probs, excluded_idx = calibration_weighted_predict(xb, models, device)\n",
        "        elif attack_type == 'KLD':\n",
        "            probs, excluded_idx = hybrid_kl_predict(xb, models, device)\n",
        "        else:\n",
        "            probs, excluded_idx = mce_oracle_predict(xb, models, device)\n",
        "        max_prob = float(probs.max())\n",
        "\n",
        "        pred = int(np.argmax(probs))\n",
        "        correct = 1.0 if pred == yb else 0.0\n",
        "\n",
        "        true_class = float(probs[yb])\n",
        "        loss = -np.log(true_class + eps)\n",
        "\n",
        "        entropy = -float(np.sum(probs * np.log(probs + eps)))\n",
        "\n",
        "        sorted_probs = np.sort(probs)[::-1]\n",
        "        margin = float(sorted_probs[0] - sorted_probs[1])\n",
        "\n",
        "        all_features.append([correct, max_prob, loss, entropy, margin])\n",
        "        all_membership.append(member_label)\n",
        "\n",
        "    all_features = np.array(all_features, dtype=np.float32)\n",
        "    all_membership = np.array(all_membership, dtype=np.int64)\n",
        "\n",
        "    return all_features, all_membership"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "0af9ea48-c3b8-4f6d-9cab-4e95f2abb47b",
      "metadata": {
        "id": "0af9ea48-c3b8-4f6d-9cab-4e95f2abb47b"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "def mce_oracle_predict(x_tensor, ensemble_models, device):\n",
        "    all_predictions = []\n",
        "    for model in ensemble_models:\n",
        "        model.eval() # Set model to evaluation mode\n",
        "        with torch.no_grad():\n",
        "            output = model(x_tensor.unsqueeze(0).to(device))\n",
        "            # Get probabilities\n",
        "            probabilities = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
        "            all_predictions.append(probabilities)\n",
        "\n",
        "    predictions = np.array(all_predictions) # Shape: (num_models, num_classes)\n",
        "\n",
        "    top_labels = [np.argmax(p) for p in predictions]\n",
        "\n",
        "    # Handle cases where top_labels might be empty\n",
        "    if not top_labels:\n",
        "        return np.zeros(predictions.shape[1]), 0\n",
        "\n",
        "    # Find the majority label among the top predictions of all models\n",
        "    majority_label_counts = Counter(top_labels)\n",
        "    majority_label = majority_label_counts.most_common(1)[0][0]\n",
        "\n",
        "    # Calculate confidence of each model in the majority label\n",
        "    label_confidences = [p[majority_label] for p in predictions]\n",
        "    # Exclude the model with the *lowest* confidence in the majority class\n",
        "    excluded_idx = np.argmax(label_confidences)\n",
        "\n",
        "    # Remove the predictions of the excluded model and average the rest\n",
        "    remaining_preds = np.delete(predictions, excluded_idx, axis=0)\n",
        "    final_pred = np.mean(remaining_preds, axis=0)\n",
        "\n",
        "    return final_pred, excluded_idx\n",
        "\n",
        "def evaluate_mce_on_test(dataset, models, device):\n",
        "    correct = 0\n",
        "    exclusion_counts = np.zeros(len(models), dtype=int)\n",
        "    total_samples = len(dataset)\n",
        "\n",
        "    print(f\"\\nEvaluating MCE Oracle on {total_samples} test samples...\")\n",
        "    for i in range(total_samples):\n",
        "        x_tensor, y_true = dataset[i]\n",
        "\n",
        "        pred_probs, excluded = mce_oracle_predict(x_tensor, models, device)\n",
        "        y_pred = np.argmax(pred_probs)\n",
        "\n",
        "        if y_pred == y_true:\n",
        "            correct += 1\n",
        "\n",
        "        exclusion_counts[excluded] += 1\n",
        "\n",
        "    accuracy = correct / total_samples\n",
        "    print(f\"\\nMCE Oracle Accuracy on full test set: {accuracy * 100:.2f}%\")\n",
        "    print(\"Model Exclusion Counts:\")\n",
        "    for i, count in enumerate(exclusion_counts):\n",
        "        print(f\"   • Model {i+1}: excluded {count} times\")\n",
        "\n",
        "    return accuracy, exclusion_counts\n",
        "\n",
        "\n",
        "# acc_mce, exclusion_stats = evaluate_mce_on_test(full_test_eval, models, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "797bf0df-2be6-4af2-b3b6-3cba73126a22",
      "metadata": {
        "id": "797bf0df-2be6-4af2-b3b6-3cba73126a22"
      },
      "source": [
        "# MCE ATTACK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "dff7649b-a243-494c-b906-a3f20e9c1bcc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dff7649b-a243-494c-b906-a3f20e9c1bcc",
        "outputId": "1ff72c77-15b0-496d-b9ee-6288238a9fca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n",
            "11000\n",
            "12000\n",
            "13000\n",
            "14000\n",
            "15000\n",
            "16000\n",
            "17000\n",
            "18000\n",
            "19000\n",
            "20000\n",
            "21000\n",
            "22000\n",
            "23000\n",
            "24000\n",
            "25000\n",
            "26000\n",
            "27000\n",
            "28000\n",
            "29000\n",
            "30000\n",
            "31000\n",
            "32000\n",
            "33000\n",
            "34000\n",
            "35000\n",
            "36000\n",
            "37000\n",
            "38000\n",
            "39000\n",
            "40000\n",
            "41000\n",
            "42000\n",
            "43000\n",
            "44000\n",
            "45000\n",
            "46000\n",
            "47000\n",
            "48000\n",
            "49000\n",
            "0\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "MCE Features:\n",
            "Member Feature Shape: (50000, 5)\n",
            "Member Labels Shape: (50000,)\n",
            "Nonmember Feature Shape: (10000, 5)\n",
            "Nonmember Labels Shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "#collect MCE features which will be used with classifer\n",
        "mce_x_member, mce_y_member = collect_features(full_train_eval, models, member_label = 1, attack_type = 'MCE', ece_scores = None, device = device)\n",
        "mce_x_nonmember, mce_y_nonmember = collect_features(full_test_eval, models, member_label = 0, attack_type = 'MCE', ece_scores = None, device = device)\n",
        "\n",
        "print(\"MCE Features:\")\n",
        "print(\"Member Feature Shape:\", mce_x_member.shape)\n",
        "print(\"Member Labels Shape:\", mce_y_member.shape)\n",
        "print(\"Nonmember Feature Shape:\", mce_x_nonmember.shape)\n",
        "print(\"Nonmember Labels Shape:\", mce_y_nonmember.shape)\n",
        "\n",
        "mce_attack_x = np.vstack([mce_x_member, mce_x_nonmember])\n",
        "mce_attack_y = np.concatenate([mce_y_member, mce_y_nonmember])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "f5ba6349-77c9-4a46-a640-311b444e089e",
      "metadata": {
        "id": "f5ba6349-77c9-4a46-a640-311b444e089e"
      },
      "outputs": [],
      "source": [
        "attack_aucs = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "73aa8653-da42-4cf9-9da1-548060f420ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73aa8653-da42-4cf9-9da1-548060f420ce",
        "outputId": "5ab40067-b397-4f8c-ff9d-a51dc82cedfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MCE AUC: 0.510471232\n",
            "[{'model': 'MCE', 'AUC': np.float64(0.510471232), 'Advantage': np.float64(0.01758000000000004)}]\n"
          ]
        }
      ],
      "source": [
        "mce_attack_scores = clf.predict_proba(mce_attack_x)[:, 1]\n",
        "\n",
        "mce_auc = roc_auc_score(mce_attack_y, mce_attack_scores)\n",
        "print(\"MCE AUC:\", mce_auc)\n",
        "\n",
        "mce_fpr, mce_tpr, thresholds = roc_curve(mce_attack_y, mce_attack_scores)\n",
        "mce_advantage = (mce_tpr - mce_fpr).max()\n",
        "\n",
        "attack_aucs.append({'model': 'MCE', 'AUC': mce_auc, 'Advantage': mce_advantage})\n",
        "print(attack_aucs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "fe2cb710-43b7-4b18-96b7-bd4fac726b9d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe2cb710-43b7-4b18-96b7-bd4fac726b9d",
        "outputId": "96ba3131-7ec1-4e0d-f2bb-0a28b540c897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model under attack: MCE\n",
            "Attack AUC: 0.510471232\n",
            "Attack Advantage: 0.01758000000000004\n"
          ]
        }
      ],
      "source": [
        "for attack in attack_aucs:\n",
        "    print(f\"Model under attack: {attack['model']}\")\n",
        "    print(f\"Attack AUC: {attack['AUC']}\")\n",
        "    print(f\"Attack Advantage: {attack['Advantage']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "af196b6c-6bf5-436b-9c15-c3f8178343a7",
      "metadata": {
        "id": "af196b6c-6bf5-436b-9c15-c3f8178343a7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}